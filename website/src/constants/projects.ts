// This file is auto-generated. Do not edit manually.
import { Project } from "./projects-page-config";

export const projects: Project[] = [
  {
    "id": "project-9800",
    "name": "MediMate",
    "case": "avi",
    "whatIsProject": "MediMate is an intelligent digital assistant designed to streamline and personalize medical onboarding for patients. Users can easily upload documents (like insurance cards and medical reports) by taking photos, which are then validated. What makes MediMate unique is its conversational approach, available in both text and audio modes. It engages patients in a dynamic dialogue, asking only relevant follow-up questions uniquely tailored to their age, reason for visit, and previously shared data, thus preventing irrelevant inquiries. This adaptability also makes it particularly suitable for users like the elderly, as the process can be completed without any writing. Our system reads and comprehend these documents with impressive accuracy, ensuring high information quality. ",
    "howBuilt": "MediMate is built as both a mobile and web application. Its core intelligence leverages Google's Gemini LLM for natural language understanding within the conversational interface (text/audio), precise document analysis and validation, and generating adaptive questions. We integrated Optical Character Recognition (OCR) to extract text from uploaded images of documents, including tables. The application facilitates direct camera access for seamless document submission. Our stack combines Python for the backend, utilizing FastAPI to handle requests from the React frontend, process data, and return responses. For audio processing and transcription, we employ OpenAI's Whisper. Finally, all patient data and extracted information are processed and structured to create the doctor's summary.",
    "difficulties": "Ensuring high accuracy of OCR and LLM interpretation across diverse medical document formats, especially large tables, was challenging. Designing a truly adaptive conversational logic that felt natural and efficiently gathered only necessary information required careful iteration. Integrating Python (FastAPI/Flask) with React to deliver a well-functioning backend-frontend required creative backend choices under time constraints. Finally, achieving reliable speech recognition beyond our text MVP",
    "oneSentencePitch": "MediMate transforms medical onboarding into a seamless, personalized experience for patients using an intelligent speech and text assistant, delivering doctors perfectly prepared, actionable insights before every visit.",
    "githubUrl": "https://github.com/ThoranTschoepe/cdtm_hack",
    "videoUrl": "https://www.youtube.com/watch?v=5qjtPFUH56I",
  },
  {
    "id": "project-8010",
    "name": "Ovita",
    "case": "avi",
    "whatIsProject": "Avi",
    "howBuilt": "With motivation and grit\n",
    "difficulties": "Nothing",
    "oneSentencePitch": "Intelligent Patient Intake & Clinical Assistant",
    "githubUrl": "https://github.com/SiddKay/Epoch-CDTM-Hacks",
    "videoUrl": "https://drive.google.com/file/d/1U7pStkNcQncoeNrqIMufhoy7L0OxKeMQ/view?usp=sharing",
    "demoUrl": "https://epoch-cdtm-hacks.vercel.app/doc , https://epoch-cdtm-hacks.vercel.app/ , https://epoch-cdtm-hacks-mobile.vercel.app"
  },
  {
    "id": "project-6740",
    "name": "Avi Intake Wizard (AVA)",
    "case": "avi",
    "whatIsProject": "Our project introduces Ava, an AI-driven digital avatar that reimagines the patient intake process. Instead of filling out static forms, patients interact with Ava through natural conversation, via voice or chat, before their appointment. Ava guides them through a personalized check-in, collecting medical history, symptoms, and important documents. The result is a seamless, human-like experience for patients and a fully pre-populated patient profile for healthcare staff. Ava helps reduce wait times, minimizes repetitive questions, and frees up administrative resources, creating value on both sides of the reception desk for potentially over 100,000 clinics in Germany.",
    "howBuilt": "We developed Ava using React for a leightweight frontend and Flask (Python) on the backend to handle all API logic and data flow. At its core, Ava uses OpenAI’s GPT-4o and GPT-4o mini for multimodal and conversational intelligence, enabling fluid, context-aware interactions. For voice interaction, we integrated separate speech-to-text and text-to-speech APIs. We also experimented with Mistral AI as an open-source alternative for text-based language processing. Lovable AI’s tooling supported our full-stack development.",
    "difficulties": "Early on, we spent too much time planning in detail instead of iterating. Our ambitious vision led to overly siloed development, each team member built isolated features that didn’t integrate well. We learned that fast, cross-functional prototyping and small PoCs would have helped us move faster and align more effectively. Connecting frontend, backend, and AI components also posed technical challenges, especially around data formats and the complexity of medical language.",
    "oneSentencePitch": "Ava is an AI-powered avatar that transforms patient check-in into a natural, conversational experience, saving time for medical staff and creating a smoother, more personal first impression for patients.",
    "githubUrl": "https://github.com/freshetomate17/avi-intake-wizard",
    "videoUrl": "https://www.youtube.com/watch?v=EMqP1742KS0"
  },
  {
    "id": "project-1374",
    "name": "medvoice",
    "case": "avi",
    "whatIsProject": "Medvoice empowers all demographics to use digital healthcare services: We improve clinical efficiency by streamlining patient intake and medical report digitalization using real-time conversational and personalized AI phone calls. This approach invites even elderly and digitally averse patients. A voice agent guides patients through medical history and symptom-checking, reducing administrative workload and minimizing errors from incomplete information. Patients can upload relevant medical documents via SMS links, and we use OCR to process paper reports for seamless database integration. Beyond data collection, our system will detect blind spots—for example, missing prescriptions for chronic conditions—and provide real-time feedback to improve healthcare insights.\n",
    "howBuilt": "We built the system using GPT-4-realtime for natural patient interaction and Twilio for voice and messaging. The entire architecture, including the voice agent, server, and AI, is developed in Python, ensuring flexibility and scalability. Patients upload documents via SMS links, which our server processes using GPT-4-powered OCR for seamless integration. Data is stored in a database where it can be retrieved for future use.",
    "difficulties": "Since a significant user group is averse to using apps and sharing data, we had to come up with a very simple solution for the user, to really solve their problem. On the technical side, combining the various tools and agents together proved challenging. Since we focused on low-barrier usage, we used the beta GPT-4-realtime model for seamless conversations. This proved very challenging due to a lack of proper API documentation. We spent a lot more time than expected on details that would have \n",
    "oneSentencePitch": "medvoice makes digital healthcare services accessible to everyone and saves patients and medical staff time and improves care quality through an conversational AI-powered phone assistant.",
    "githubUrl": "https://github.com/Skario2/VoiceMed",
    "videoUrl": "https://drive.google.com/file/d/1pXnpl6O3lyUE67qghvLW_nCulqExGtef/view",
  },
  {
    "id": "project-5644",
    "name": "TradeX",
    "case": "Trade Republic",
    "whatIsProject": "TradeX is the new way to empower every individual to invest in whatever aligns best with their needs. We focus on motivating the individual through community spirit and education, specifically by implementing the personalized chatbot, a visual to show your progress in reaching your goals, and an anonymized view of what the most successful portfolios invested in. On top of that, TradeX also approaches empowerment and democratization from the private market side. We allow individuals to invest in the private market, without needing large financial capital. This is something that is available nowhere else.",
    "howBuilt": "We've build the product using state-of-the-art computer systems. Leveraging a React Framework together with the csv-data we got from Trade Republic as well as the API, we could gain momentum in building the next big thing in Finance.",
    "difficulties": "The main difficulty we faced was integrating the OpenAI API into our project, especially issues linked to permissions with the key. Moreover, it was fun but challenging to completely think outside the box and come up with new ideas.\n",
    "oneSentencePitch": "TradeX offers novel personalized insights on an individual’s financial activities, motivational community spirit, and allows anyone and everyone to invest in private equities - something that is not possible elsewhere today.",
    "githubUrl": "https://github.com/constantin-albrecht/trade_republic_cdtm?tab=readme-ov-file/",
    "videoUrl": "https://www.youtube.com/watch?v=J-zTsc38IdI"
  },
  {
    "id": "project-1613",
    "name": "VisitEase",
    "case": "avi",
    "whatIsProject": "Planning to visit a healthcare professional? In most cases patients forget to bring relevant medical records like medical history, recent lab results and specific medication names. This drastically increases complexity for doctors to effectively assist and provide the best care possible. VisitEase is the solution - it is about enabling better healthcare for patients of all technical backgrounds by allowing them to easily and dynamically upload snapshots of their data. No more forgetting documents, confusion and unnecessary waiting. As a doctor, you also profit from being able to view a patient's data in a structured dashboard with dynamic interactions powered by LLMs. Through technical innovation, VisitEase shapes the future of patient visits and acts as a cornerstone in medical tech.",
    "howBuilt": "The infrastructure of VisitEase can be divided into a front- and backend. For the backend we set up a Flask server that uses multiple POST and GET requests to login and signup patients to our platform, upload and store images and convert them to .pdf, call the Gemini API in order to make sense of the uploaded pdf data and call the Firestore database to retrieve the data. In terms of UI we implemented two separate responsive frontends using Svelte and React: \nVisitEase, the app used by patients in order to upload their data responsively between mobile or desktop and \nVisitEaseDoc, the app for doctors to view the structured data dynamically. \nWe are using Vercel to host the frontend and Rendr to host the logic run in the background in order to provide a working prototype url.",
    "difficulties": "“What platform should we build for?” was an important question throughout the hackathon. After conferring with the avi team we decided to stick to our approach and build a responsive web app. Another technical difficulty was implementing a talking agent because sharing audio between the front- and backend using requests isn’t trivial. We solved the problem by using the OpenAI API to process user audio, generate a text response and return a new stream of audio using the Gemini text-to-speech API.",
    "oneSentencePitch": "A structurization engine for complex, incomplete and variable data.",
    "githubUrl": "https://github.com/amribic/VisitEase",
    "videoUrl": "https://www.youtube.com/watch?v=swTmXxo5_c0",
    "demoUrl": "https://visit-ease.vercel.app/"
  },
  {
    "id": "project-4047",
    "name": "Wealthie",
    "case": "Trade Republic",
    "whatIsProject": "Wealthie makes investing easier and more human. Financial literacy is still a privilege, and most people find investment decisions overwhelming. Traditional apps are cluttered with complex charts and numbers that don’t mean much to many users. Wealthie changes that: no more frustrating charts. See your savings, top-up for automatic investments and a personalized wrap. Dive deeper, look through your portfolio and read our AI-summarized news relevant to it. We also simplified the build-your-wealth process - buying is the only available option on the main screen:) Do you have more questions? – ask our chatbot about anything (also with short-cuts). On the top we enabled Investor Briefings to all users –  now everyone can ask questions to AI-generated CEOs by clicking on a stock-icon.",
    "howBuilt": "For our project, we used Mistral AI’s API (mistral-medium-latest) through Le Plateforme to help with portfolio analysis, chatbots, and news summaries. This way, users could interact with AI-powered tools to get personalized financial insights. We also used Beyond Presence to create AI-driven videos, allowing CEOs to answer user questions virtually. For the data analysis part, we used Pandas to process and deliver custom insights. The backend was built in Python, while the frontend used Svelte. We created FastAPI for connection between frontend and backend. We hosted everything on Railway for deployment. To generate wrapped insights, we pulled data from the Trade Republic GitHub repository and used their API to match ISINs to the right stocks.",
    "difficulties": "We had so many ideas that we were so indecisive at first. Choosing anything had an opportunity cost. So we could not start coding until 11 AM Saturday, we voted and prioritized things for development for our MVP. Then we started to develop. We tried to collect real-time news from the web pages, but were blocked by anti-bot protection and therefore had to generate them with AI. Even though we had a .gitignore, the .env file was pushed into our public repository (luckily we deleted it in time).",
    "oneSentencePitch": "Investments Made Simpler",
    "githubUrl": "https://github.com/tboehnel/hackathon-4047",
    "videoUrl": "https://www.youtube.com/watch?v=v0_9OWTU1Nw",
    "demoUrl": "https://meticulous-luck-production.up.railway.app/"
  },
  {
    "id": "project-4688",
    "name": "QuikPatient",
    "case": "avi",
    "whatIsProject": "We agree with avi's view of making healthcare less of a nightmare, for both patients and doctors! Check in the day before, and go to your appointment stress-free and paper-free. Scan all of the important documents, and let AI detect the text, transmit the document and a quick summary of them to your doctor. Instead of spending time drowning in a sea of papers, your healthcare providers will us their time to take care of your needs.",
    "howBuilt": "This project uses Python for the backend, with a focus on document processing through a process document function, which employes Google's OCR library,Tesseract, to extract text and metadata from PDFs. The extracted text is prompted to Gemini 2.5 pro to provide a summary of the crucial information in the documents. In the future, we envision this summaries (together with the original documents) to be provided to the doctors, avoiding having to read tens of papers and getting an overview of what really matters. The frontend is built with React Native.",
    "difficulties": "We initially spent a lot of time testing a lot of different things and being stubborn about them, which resulted in a lot of time wasting and we were not able to achieve what we envisioned. Nonetheless, we learned a lot about organization and how to approach hackathons so we are very happy and looking forward to the next one.",
    "oneSentencePitch": "Efficient Patient Check-in",
    "githubUrl": "https://github.com/maazahmed02/lomazo",
    "videoUrl": "https://drive.google.com/file/d/1Y6h7PQ_K58_8dfsSalh3OvVii8piv0Bt/view?usp=sharing"
  },
  {
    "id": "project-1090",
    "name": "Finspire",
    "case": "Trade Republic",
    "whatIsProject": "Wealthify – Voice-First Investing for All\n\nIn today’s fintech landscape, democratizing access to investing is crucial. During the Trade Republic Hackathon, we developed Wealthify, a voice-first interface that simplifies investing for all, including those with visual impairments, tech aversions, or busy lifestyles. With natural language commands, users can check portfolios, execute trades, and get market updates hands-free, bridging accessibility gaps in finance.\n\nCore Features:\n\nVoice Commands: “What’s my portfolio value?” or “Buy €100 of Tesla.”\n\nNatural Language Processing: Parses commands for secure, accurate transactions.\n\nAccessibility-First Design: Fully hands-free, WCAG-compliant interface.\n\nMarket Insights: Real-time data delivered in conversational speech.",
    "howBuilt": "LLMs Function calling concept-openai- Text to speech for frontend loveble",
    "difficulties": "Too many Ideas- and Implementing Front-end",
    "oneSentencePitch": "Future of Fintech re-imagined",
    "githubUrl": "https://github.com/imanigma/TradeRepublic_CDTMHacks25",
    "videoUrl": "https://www.youtube.com/watch?v=IAOHzzvcX2s",
    "demoUrl": "https://preview-08806e67--perfect-pixel-crafting-kit.lovable.app/"
  },
  {
    "id": "project-2517",
    "name": "Interstellar Exchange",
    "case": "Trade Republic",
    "whatIsProject": "Our Trade Republic redesign breaks free from traditional banking layouts. Instead of static lists and tables, users can organize their financial information spatially, creating meaningful connections between different aspects of their wealth. The platform allows users to create visual representations of their financial goals, track investments through interactive charts, and maintain a holistic view of their financial health. By leveraging modern design principles and intuitive interactions, Interstellar Exchange makes financial management more accessible and engaging for users of all backgrounds.",
    "howBuilt": "The project is built using a modern tech stack centered around React and TypeScript, providing a robust foundation for building complex user interfaces. We utilized Vite for fast development and optimized builds, while shadcn-ui and Tailwind CSS enabled us to create a polished, responsive design system. The application features a custom canvas implementation for financial data visualization, and interactive components. We implemented a modular architecture with separate services for data management, custom hooks for state management, and reusable components for consistent user experience. ",
    "difficulties": "A significant challenge was designing an intuitive user experience that would make complex financial concepts accessible to users while maintaining flexibility and professionalism, integrating diverse modules (voice, GPT, animation) into a seamless UX involved debugging cross-module compatibility issues.\nWe overcame these challenges through iterative design, performance profiling, and careful consideration of user feedback. ",
    "oneSentencePitch": "Interstellar Exchange is an innovative financial visualization platform that transforms traditional banking interfaces into an intuitive experience where users can organize, visualize, and interact with their financial data in a more natural and engaging way.",
    "githubUrl": "https://github.com/CDTMHackathon2025/fresh-canvas-unfold",
    "videoUrl": "https://www.youtube.com/watch?v=PeW8F32_YEc",
    "demoUrl": "https://lovable.dev/projects/f1df7593-51dd-461b-b243-dd589756bf33"
  },
  {
    "id": "project-4775",
    "name": "N/avi",
    "case": "avi",
    "whatIsProject": "N/avi is a digital onboarding platform that simplifies how patients share medical information with providers. Using cutting-edge AI and OCR technologies, it transforms legacy paper forms into structured digital data, capturing symptoms, insurance details, vaccination history and medical records, via an intuitive, step-by-step user experience. \n\nIt makes the onboarding as easy as taking a selfie while also saving the provider the pain of going through millions of documents yearly. \n\nThe benefits don't stop there - with our well-structured data it enables other data-driven applications by providing the data in a structured and clean way. ",
    "howBuilt": "The project is built on a full-stack Next.js web application. The frontend is developed using React, styled with Tailwind CSS, and enhanced by a custom UI component library to deliver a clean, responsive, and well-structured user experience. For state management, we use Zustand to maintain consistency across multi-step forms.\nThe backend integrates Google’s Vertex AI API, specifically the Gemini 2.0 Flash model, to intelligently parse medical documents. Under the hood it leverages a multi-pass data processing pipeline for high accuracy and data reliability.",
    "difficulties": "From a technical viewpoint implementing reliable OCR on heterogeneous, low-quality medical forms was challenging; we had to fine-tune preprocessing and error-correction steps to reduce inaccuracies. On a more personal note, even though the challenge was for a health care provider the we didn’t care for our health during the hackathon, so keeping your eyes open and staying motivated was definitely a challenge we faced and conquered as a team.\n",
    "oneSentencePitch": "N/avi: A smarter way to manage your medical records and navigate the healthcare system - streamlined, secure, and built with patients in mind.",
    "githubUrl": "https://github.com/Max-vS/avi-case",
    "videoUrl": "https://www.youtube.com/watch?v=2DGlx0Mp2yE"
  },
  {
    "id": "project-3944",
    "name": "FinEdu AI",
    "case": "Trade Republic",
    "whatIsProject": "EduFinAI redefines how people engage with their finances by introducing an intelligent, LLM-powered voice assistant that delivers real-time, conversational insights into their investments. By combining education with action, it helps users better understand their portfolios, ask meaningful questions, and receive clear, hyper-personalized answers. Complex data is transformed into intuitive, visual context—making financial decisions simpler, smarter, and more human. This is more than just a new interface; it’s a leap toward financial empowerment through hyper-personalized, accessible conversations.",
    "howBuilt": "We built the project using React and TypeScript, with Tailwind CSS for styling. Supabase handles backend, authentication, and database. Voice input is managed via the Web Audio API, and context-aware responses are generated using the OpenAI API. Framer Motion provides animations, Lucide React supplies icons, and React Context manages global state.",
    "difficulties": "Our biggest challenge was integrating the various technical components, such as the LLM and the conversational agent, while ensuring secure and smooth data exchange. Additionally, managing the interaction between different programming languages added complexity to the development process. Furthermore, it was a challenge to ensure that the AI understands the knowledge level of the person and adopts correspondingly. ",
    "oneSentencePitch": "FinEdu AI is an intelligent voice assistant that replaces complex app navigation with a simple and hyper-personalized, conversational way to manage your finances - no more complex UI and tapping in the app needed.",
    "githubUrl": "https://github.com/azzabaatout/cdtm-hacks",
    "videoUrl": "https://www.youtube.com/watch?v=8MqSNhjHQOU",
  },
  {
    "id": "project-3009",
    "name": "PeopleWorks",
    "case": "beam",
    "whatIsProject": "Our Hack fully automates the work of facilitating feedback in the moments in really matters for employees with minimal friction:\nOn completion of a milestone or fuck-ups the HRBP agent is triggered to facilitate feedback and employee growth\nFirst, the relevant employee data is gathered, inc. their career goals, their recent project contributions, and their history competency assessment\nNext, an individualized questionnaire is created to collect specific feedback\nThen, all your involved teammates are called and interviewed on your development\nLastly, all this feedback is aggregated and mapped against the competencies and supported with real quotes\nEvery employee has better transparency about their development than ever before",
    "howBuilt": "Core Engine are build on AgentExecutors with a loooot of tools.\nBackend: Mostly Python, FastAPIs, Eleven Labs, OpenAI, Mistral Medium 3, Langchain, Cursor\nDatabase: Supabase\nFrontend: Lovable, V0\nAdditional Inactive tools: Slack bot, beyond presence + livekit for a video feedback session",
    "difficulties": "Technical Difficulties:\nExtracting structured data from unstructured feedback formats with pydantic schemas and zero-shot classification. \nIntegrating the main agent with external tools -- mainly with eleven labs and beyond presence. Extracting and processing transcripts from these were the longest processes in our tool.\nGetting the tool call order and performance right: With tools interacting with superbase, free text transcripts, and external agents (including a Slack bot api)",
    "oneSentencePitch": "PeopleWorks enables continuous, personalized and fully automated peer-to-peer feedback across organisations.",
    "githubUrl": "https://github.com/kraftfrosch/hackfleisch",
    "videoUrl": "https://www.youtube.com/watch?v=Oyvrw4j8W24",
    "demoUrl": "https://v0-employee-management-software-rho.vercel.app/"
  },
  {
    "id": "project-9874",
    "name": "Opus - Workforce",
    "case": "beam",
    "whatIsProject": "Opus is an AI-native workforce platform designed to automate repetitive, high-volume tasks across HR, customer support, and data analysis:\nHR: Our HR Management Workforce integrates with Personio to automate tasks like job postings, approving leave requests, or updating employee data—triggered by a simple Slack message.\nCustomer Support: Opus connects to your support call-hotline and email, managing client interactions end-to-end—answering FAQs, issuing refunds, escalating issues, and resolving them.\nData Analysis: Employees get instant answers to data questions—like user numbers or retention trends—via Slack. Opus pulls, processes, and delivers insights from your databases and documents in seconds\n\nAltogether this lets your company scale on demand, flexible, cheap so you can stay focused!",
    "howBuilt": "We built an important part of Opus using modern AI agent frameworks and low-code tools of Beam. The core email support flow runs on Beam, handling ingestion, LLM-powered replies, data extraction, and automated responses. Slack workflows (e.g., HR, data analyst tasks) are built with n8n, triggered via webhooks from a custom Slack app, and powered by LLMs or backend agents running browser-based flows. All agents are connected to an observability layer tracking logs, events, and process states. Our observability platform is built with Lovable&Cursor using React, Vite, and Supabase; the landing page is made in Framer. Voice agents are powered by VAPI with Twilio’s phone integration, capable of handling calls, triggering webhooks, extracting data, and sending emails (w/ make.com).",
    "difficulties": "We had to learn Beam fast—tooling like HTTP requests and saving/publishing states weren’t intuitive at first. Slack auth across Beam, n8n, and our backend was tricky. Personio’s complexity often overwhelmed our agents, so context window balance was key. VAPI’s tool call functionality turned out to be  tricky too. Non-tech: Understanding PedalWork’s customer service workflows took deep research. A structured ideation session helped us prioritize problems using a wow-effect, impact, effort matrix.",
    "oneSentencePitch": "Opus is your scalable AI-powered workforce, automating HR, customer support, and analytics to supercharge organizational productivity across all departments.",
    "githubUrl": "https://github.com/Musti7even/workflow-orchestrator-insights.git",
    "videoUrl": "https://www.youtube.com/watch?v=3JpwL6lwU84",
    "demoUrl": "https://wondrous-tetragon-150018.framer.app/"
  },
  {
    "id": "project-5280",
    "name": "MOV Health",
    "case": "avi",
    "whatIsProject": "MOV Health is both a website and PMS, that collects patients information in an empathetic way.\n\nUsers can self service (book appointments, receive medical advice, and upload documents) from a chatbot in the homepage. This solves the pain of going through digital anamnesis.\n\nDoctors can extract relevant information of appointments and patient history from their dashboard.\n\nIt's unique because it is user centric. It has been designed to take into consideration the goals of the users in every step of the process.\n",
    "howBuilt": "FRONT END\nReact 18\nTypeScript\nVite\nTailwind CSS\nShadcn UI Components\nReact Router DOM\nReact Query\nSupabase Client\nReact Hook Form\nZod for validation\nVarious Radix UI components for accessible UI elements\nLovable\n\nBACK END\nFastAPI\nPython 3.x\nMistral AI Integration\nLangChain\nPydantic\nUvicorn\nPython-dotenv\n",
    "difficulties": "One of the main challenges we faced was working with the Mistral API, as it's still quite new and lacks sufficient documentation. While we were trying to integrate it programmatically, I discovered that agents currently seem to be usable only through the GUI, with no clear guidance on multi-agent workflows or how to incorporate chain-of-thought (CoT) reasoning within agents. This made it difficult to build more complex or automated interactions. Additionally, some API responses were vague ...",
    "oneSentencePitch": "MOV Health makes medical onboardings streamlined and useful, both for patients and healthcare professionals.",
    "githubUrl": "https://github.com/Pranjal7852/cdtm-hack-avi",
    "videoUrl": "https://www.loom.com/share/9954ae25a4464ad89207efd95234d0c7?sid=c4b62f88-a3e9-456d-9529-7233c088a8c5",
    "demoUrl": "https://mov-health-hub-page.lovable.app"
  },
  {
    "id": "project-1112",
    "name": "trAIdable capital",
    "case": "Trade Republic",
    "whatIsProject": "Our project is a next-generation investing platform inspired by Trade Republic, built for retail investors who want a more interactive and personalized stock experience. It features real-time stock data, curated news, and \"story-style\" updates for followed and owned stocks—similar to Instagram Stories—powered by AI-driven news explanations. Users receive daily top gainer/loser highlights with context, a yearly \"Spotify Wrapped\"-style recap of their portfolio, and a voice assistant that lets them explore, track, and trade stocks via natural conversation.",
    "howBuilt": "We built the project using a modern full-stack setup: FastAPI and Python on the backend, Next.js on the frontend, and OpenAI’s Realtime API for natural language understanding and AI explanations. Yahoo Finance powers our stock data, Finnhub provides real-time news, and Perplexity helps identify the most relevant headlines behind price movements. We use caching to optimize API usage and ensure fast performance. Our “story” feature and voice assistant are driven by GPT with function calling, enabling real-time interactions and personalized insights.",
    "difficulties": "One major challenge was mapping real-time price movements to relevant news in a reliable, explainable way. Since APIs like Finnhub provide raw news without clear cause-effect links, we used Perplexity and GPT to intelligently extract and summarize plausible reasons. We also had to design a performant caching system to avoid excessive API calls while keeping the user experience real-time and responsive.",
    "oneSentencePitch": "The better Trade Republic",
    "githubUrl": "https://github.com/WrappedSuperClass/CDTM_Trade_Republic_BE",
    "videoUrl": "https://www.youtube.com/watch?v=U0g48UA-YW4",
    "demoUrl": "https://cdtm-trade-republic-be-9pp2.vercel.app/"
  },
  {
    "id": "project-1277",
    "name": "MediMate",
    "case": "avi",
    "whatIsProject": "Our project makes the patient intake process smoother and more personal by using an interactive avatar that talks with patients before they see their doctor. Patients can upload medical documents, describe their symptoms in natural conversation, and share the reasons for their visit. The system processes this input and delivers a clean, structured summary to the doctor via a dashboard. This reduces time spent on repetitive questions, minimizes errors, and ensures that doctors are better prepared before seeing the patient. It’s intuitive for patients, efficient for doctors, and designed to bring clarity to the often messy pre-visit workflow.",
    "howBuilt": "We built a patient-facing Swift-based iOS app that integrates with Apple HealthKit and uses the camera to scan documents. It connects to a Python FastAPI backend, where “mistral-medium-latest” processes patient files and images. Real-time voice and video with an AI avatar is enabled by LiveKit, powered by OpenAI and Google Gemini models. Beyond-Presence adds emotional and contextual awareness. Doctors use a React + TypeScript dashboard built with Lovable to review structured data, which can be exported in the dashboard.\nThe application is end-to-end connected, such that real patient data reaches the doctor dashboard. Both the dashboard and the webserver are deployed on Google Cloud.",
    "difficulties": "A key challenge was unifying responses from multiple APIs as well as unstructured formats into a structured format. Integrating the AI avatar was especially complex and time-intensive. Lastly, coordinating smooth communication across diverse frontend, backend, and real-time systems also required creative problem-solving.",
    "oneSentencePitch": "Talk to an AI, not a clipboard — your doctor gets the full story.",
    "githubUrl": "https://github.com/bestler/CDTM-Hackathon",
    "videoUrl": "https://www.youtube.com/watch?v=zucgH1dtHeU",
    "demoUrl": "https://dashboard-1056955526781.europe-west3.run.app"
  },
  {
    "id": "project-7269",
    "name": "MediTake",
    "case": "avi",
    "whatIsProject": "Our app lets first-time patients complete every intake task: insurance scan, wearable sync, med-and-vaccine photo capture, and gap-aware health questions, all in under a minute on their own phone, generating a digital “boarding pass” that guides them straight to the exam room. A reception swipe of the eGK handles the mandatory VSDM check, so no front-desk stop is needed. Behind the scenes the data is written as fully coded KBV-FHIR bundles, and the GP’s cockpit instantly shows a few-line résumé, reconciled med list, and AI-flagged risks before the visit even begins.",
    "howBuilt": "Our modern AI-powered web app combines a React (18.3.1) + TypeScript frontend with a Python 3.12 backend. It uses Supabase with vector database support for efficient document processing and retrieval, offering two processing modes for different patient groups. The frontend is built with Vite, Tailwind CSS, Shadcn UI, and Radix UI, with state handled by React Query and React Hook Form. AI integration includes OpenAI (Realtime API Beta) and Google Gemini. Development is optimized with ESLint, SWC, PostCSS, and environment management via Node.js and .env files.",
    "difficulties": "We had some difficulties implementing the real-time video conversational agent.\nDue to API constraints, it was not possible to connect a live stream of the webcam directly to an LLM in any way. To solve this, we utilised a hybrid architecture between Gemini <-> RAG <-> Openai Realtime API with a tool on the realtime API session that periodically queried video annotations that we created with Gemini and stored in a RAG storage.",
    "oneSentencePitch": "Transforming a chaotic intake into a digital boarding pass",
    "githubUrl": "https://github.com/VishiATChoudhary/patient-journey-pilot",
    "videoUrl": "https://www.youtube.com/watch?v=BpQnxbrkZ5o",
    "demoUrl": "https://preview--patient-journey-pilot.lovable.app"
  },
  {
    "id": "project-1464",
    "name": "Republica",
    "case": "Trade Republic",
    "whatIsProject": "Our project redefines banking by introducing Republica, a multimodal assistant integrated into the Trade Republic app. While traditional banks offer static interfaces, Republica enables intuitive interaction via speech and text, adapting to all users. It educates users on markets, offers investment insights, supports wealth building, and simplifies the German tax system. A personalized \"For You\" page additionally visualizes portfolio data, categorizes expenses, and delivers short market summaries and curated content. Republica transforms everyday banking into an interactive, intelligent, and accessible experience for everyone.",
    "howBuilt": "This project is built by embedding a fine-tuned LLM pipeline as a backbone to a custom-developed interface. The interface has been set up using Vite to handle builds and dev tooling, TypeScript for maintainable and developer-friendly code, React and shadcn-ui to provide ready-to-use UI components, and Tailwind CSS for styling. We have used various LLM-based tools to speed up development, such as Lovable and ChatGPT. Within the app, we enable an efficient structure for generating safe OpenAI API requests for interaction via voice and chat. We use models such as mistral-large-latest, gpt-4o-mini, whisper-1 and tts-1. Tools such as Beyond Presence and HeyGen have been employed for automated video content generation to enable a user-friendly way of conveying essential information.",
    "difficulties": "- Building a front end as developers with no front-end dev experience might result in a wild ride -> luckily, tools like Lovable can be impressively useful! most important thing is to focus on fast iteration instead of lengthy prompts\n- Making sure the other person really understands what you envision for how a feature should look like and be used when implemented -> use tools like Figma to quickly visualize your idea so other people see what you are thinking about",
    "oneSentencePitch": "The only app you need to manage every part of your financial life, to democratize wealth.",
    "githubUrl": "https://github.com/CDTM-Hackathon-2025/cosmic-cool-things",
    "videoUrl": "https://linktr.ee/ByteForce_CDTM",
    "demoUrl": "https://www.youtube.com/watch?v=wu5BNnAtn1A"
  },
  {
    "id": "project-5730",
    "name": "HealthTracker",
    "case": "avi",
    "whatIsProject": "AVI Health is a digital health platform that uses AI to automatically scan and extract data from medical documents (blood tests, vaccination records, prescriptions, and medical reports). The system provides a comprehensive dashboard where healthcare providers can instantly access patient histories, track health trends through interactive visualizations, and share information seamlessly. Built with React and Java Spring Boot, it integrates document scanning, OCR processing, and data analysis to eliminate manual data entry (but still allow it on demand) and create actionable health insights for better patient care.",
    "howBuilt": "Our tech stack combines React for the frontend, Java Spring Boot for the backend API, and Python FastAPI for AI document processing. We used OpenAI's GPT-4 Vision for optical character recognition and structured data extraction from medical documents. The database is MySQL, with JWT authentication for security and session management. The app features a responsive mobile design using Tailwind CSS, real-time data visualization with Recharts, and a document upload pipeline that processes images extracting medical data from blood tests, vaccinations histories, medication prescriptions  and medical reports. ",
    "difficulties": "The main challenge was achieving accurate medical data extraction from diverse document formats and handwritten notes. Balancing AI accuracy with processing speed required extensive prompt engineering. Integrating three different backend services (Java, Python, and database) while maintaining real-time responsiveness demanded careful API design. Also Connecting out different parts and deploying the whole system in 36 hours was quite challenging.",
    "oneSentencePitch": "Shazam for medical documents",
    "githubUrl": "https://github.com/Nikitaz1410/CDTM_Hack_2025",
    "videoUrl": "https://www.youtube.com/watch?v=G7SVT1X2zEg",
    "demoUrl": "https://avi-health.de"
  },
  {
    "id": "project-9767",
    "name": "Avi.pulse - Your one stop health data management platform",
    "case": "avi",
    "whatIsProject": "Avi.pulse automates patient intake tasks, centralizes data, and leverages AI to facilitate doctor-patient interactions. We simplify the intake of health data through intuitive tools: Scan documents with your phone, digitize insurance cards, or even mail in paperwork for digital processing. Our AI-powered OCR and autofill capabilities extract and organize data intelligently, enabling fast, vectorized querying for healthcare providers. With the auto-request functionality, patients are able to automatically request the digital transmission of documents from past doctors. We turn fragmented and scattered health data into seamless, comprehensive overviews with optional detailed document viewing.",
    "howBuilt": "avi.pulse combines a modern tech stack for performance and scalability: Supabase powers our backend and data layer, Mistral’s large-latest model extracts structured information from scanned documents and images, and OpenAI GPT-4.1 embeds documents into a vector database for instant, intelligent querying. Our Angular + Tailwind CSS frontend ensures a responsive, accessible interface that reflects the avi design language.",
    "difficulties": "The main challenges we faced were, first of all, trying to understand the patient. What is he looking for? What is he struggling with? The other thing we were primarily challenged with was the amount of different data formats that exist: While some documents are already structured pretty well (like tables), especially hand-written additions made the import process quite messy.",
    "oneSentencePitch": "avi.pulse is revolutionizing healthcare accessibility by enabling patients to easily manage all their health data - without a single stack of a paper",
    "githubUrl": "https://github.com/nictru/cdtm-avi",
    "videoUrl": "https://www.youtube.com/watch?v=NuxSYas6LXc",
    "demoUrl": "https://avi-cdtm.netlify.app/"
  },
  {
    "id": "project-4786",
    "name": "Today's growth.",
    "case": "Trade Republic",
    "whatIsProject": "We provide a simple AI agent for personal retirement finance. Users gain a clear view of how small changes in today’s spending can lead to a meaningful increase in their future pension. Showing exactly what they can do now, based on their personal expenses.\n\nAt its core is a dynamic retirement portfolio projection. Based on that, AI powers seamless optimization:\n\nAnalyzes and summarizes monthly spending\nDetects low-value subscriptions and quantifies their reinvestment impact\nDelivers personalized cancellation suggestions, ready to approve with one click\nAutomates the cancellation of selected subscriptions\nReinvests saved amount into ETFs and updates the pension projection\n\nWe aim for radical simplicity. Instead of overwhelming, we stripped away, democratizing compounding investments. \n",
    "howBuilt": "To tackle the pension gap, we built a full-stack React app, powered by a Supabase backend for seamless access to the provided financial sample data. The TR-API was used for a benchmarking data set. We developed a dynamic prediction model derived from the geometric series that estimates future savings, asset growth, and retirement income, keeping even outside factors, like inflation, in mind. To turn insights into action, we integrated GPT-4o to analyze detailed user spending, uncover behavioral patterns, and deliver personalized, AI-driven recommendations. Going further, we built an automation agent in Make, leveraging OpenAI to cancel unnecessary subscriptions and directly reallocate the savings, transforming small lifestyle changes into a source of long-term financial security. ",
    "difficulties": "Our biggest challenge was building a simple but impactful UI: Helping users immediately understand how today’s decisions affect their future, without needing to grasp complex math. Visualizing this was tough, but enabling users to cancel subscriptions directly in the app was even harder, considering a legally and technically feasible integration. We solved this by thinking outside the box and creating a seamless experience requiring minimal user effort.",
    "oneSentencePitch": "Closing tomorrow’s pension gap by optimizing today’s personal finances - making compounding assets tangible and turning them into real growth",
    "githubUrl": "https://github.com/Lovisk8lk/future-flow-insights",
    "videoUrl": "https://www.youtube.com/watch?v=KkaECUZTqAc",
    "demoUrl": "https://preview--future-flow-insights.lovable.app"
  },
  {
    "id": "project-2576",
    "name": "WorkAR",
    "case": "beam",
    "whatIsProject": "We built a system that uses AI and the Meta Quest headset to enable real-time, step-by-step visual instruction for physical tasks. One user records themselves performing a task, and our AI automatically transforms it into intuitive, contextual guidance. A second user, even with no prior experience, can then wear the headset and be visually guided through the task in AR. In the long run, this system can supervise and instruct any blue-collar worker to perform almost any task — from basic operations to complex procedures — without the need for formal training. It’s a new way to transfer human skills instantly, bridging the labor gap and redefining how work gets done.\n",
    "howBuilt": "Our system runs on the Meta Quest headset using a Unity-based application for immersive AR task guidance. On the backend, we use a Python server to manage data flow, task logic, and AI integration. For semantic understanding and task breakdown, we leverage a large language model (Gemini) to interpret recorded demonstrations and generate step-by-step instructions. For accurate object localization and spatial context within the AR environment, we use OWL-V2, enabling reliable alignment between instructions and the real world. This stack allows for near real-time, context-aware guidance that adapts to both the environment and the user’s actions.\n",
    "difficulties": "We had no prior experience with Unity or AR, so ramping up quickly was a challenge. The hardest part was minimizing end-to-end latency between the headset, Python backend, and AI services, which required optimizing data flow and asynchronous communication.\n",
    "oneSentencePitch": "Solving the skilled labor gap with AI-powered AR instructions",
    "githubUrl": "https://github.com/MichaelBonacina/WorkAR-backend & https://github.com/andreemic/workar-unity",
    "videoUrl": "https://www.youtube.com/watch?v=jQKgnva78Bg"
  },
  {
    "id": "project-3794",
    "name": "Pledge",
    "case": "beam",
    "whatIsProject": "Our solution automates end-to-end hiring by creating tailored job posts, sourcing top candidates, screening talent and conducting interviews based on your organization’s specific needs. Designed for busy HR teams and growing businesses, it combines intelligent automation with personalized workflows to deliver high-quality hires faster, more efficiently, more thoroughly and more objectively with less bias compared to humans. Compared to current state-of-the-art CV screeners, our tool can be more considerate, fair and human-centered via follow-up questions (e.g., allowing to explain resume gaps or inquiring for specific experience not given in the CV), which can also be used to proof-check data (e.g., short stays at elite universities).",
    "howBuilt": "We built our solution using the Beam platform to orchestrate autonomous agents. The front end is developed in React, originally based on a Lovable template that we later customized for a unique user experience. The backend runs on Node.js, enabling smooth API integration and scalability. We integrated LinkedIn’s API for content sharing and user authentication. Our chatbots are powered by OpenAI, enabling intelligent candidate interactions and dynamic communication throughout the hiring process.",
    "difficulties": "We faced significant challenges with the Beam platform, which was unstable and had limited documentation, hindering agent orchestration. Additionally, the case provided was hypothetical, without real customer data, making it difficult to define a concrete problem. We spent the first 24 hours refining our approach to identify a real-world issue that could be solved effectively with an agent-driven workflow.",
    "oneSentencePitch": "Streamline hiring by sourcing and screening candidates through human-centered agents.",
    "githubUrl": "",
    "videoUrl": "https://www.youtube.com/watch?v=cYkDRgcaKMQ",
    "demoUrl": "https://pedalworks-interviewee.lovable.app/"
  },
  {
    "id": "project-7535",
    "name": "ALVI",
    "case": "avi",
    "whatIsProject": "This project empowers patients visiting a new doctor for the first time by providing a comprehensive overview of their health history. Through a user-friendly mobile app, patients can conveniently upload various health documents or capture them directly using their smartphone camera. The app also securely accesses health information stored privately on the patient’s mobile device. To ensure a complete and accurate health profile, a specialized AI model identifies and prioritizes any missing documents, prompting patients accordingly. For healthcare providers, the doctor’s web interface delivers a streamlined dashboard, presenting structured and clearly organized patient data for efficient and informed medical decisions.",
    "howBuilt": "Frontend Patient: Swift/SwiftUI, Spezi Framework \n\nFrontend Doctor: React, Typescript, Loveable\n\nBackend: Next.js, Typescript, Vercel, Gemini 2.5",
    "difficulties": "- Following the documentation of Spezi or OpenCardReader\n- Converting HealthKit data into representable data structure\n- establishing the correct database schemas for medical data\n- prompting the LLMs correctly and forcing them onto a structured output in JSON\n- error handling of LLM responses",
    "oneSentencePitch": "Alvi offers effortless patient health data onboarding and pre-anamnesis via automated data processing of patient data",
    "githubUrl": "https://www.notion.so/svenolafrohr/REPOSITORIES-ALVI-1f015b29cf7d8016a724cd3a7e5234ec?pvs=4",
    "videoUrl": "https://www.youtube.com/watch?v=uqjKM2p5hlU",
    "demoUrl": "https://preview--cdtmhacks-doc.lovable.app/patients"
  },
  {
    "id": "project-9585",
    "name": "CleanNest",
    "case": "beam",
    "whatIsProject": "We build an AI agent that automatically renames files based on their content and introduces a meaningful subfolder structure. This transforms chaotic file repositories into clean, human-navigable systems, starting with Virtual Data Rooms used in high-stakes M&A deals. In these environments, poorly named files waste valuable time and create risk. Our tool enables faster access, better collaboration, and higher confidence in the data, all without requiring users to change their behavior. And beyond data rooms, the opportunity is massive: every company with Word, Excel, and PDF chaos can benefit.\n",
    "howBuilt": "We were immediately intrigued by Beam's potential. At the same time, we explored the most automatable pain points across companies - and quickly identified unstructured content management as a core weakness. Virtual Data Rooms offered a clear, high-impact starting point. Technically, we used Beam to create an \"organize\" folder and fetch file IDs. Each file is downloaded, parsed via Mistral OCR, and semantically analyzed using Mistral Medium 3. The model generates summaries, suggests meaningful file names, and proposes a logical folder structure. Finally, files are renamed and moved into the new structure - clean, fast, and fully automated.",
    "difficulties": "One challenge was that Beam doesn’t support content-dependent loops, so we used Make to handle that logic. Some key actions were missing in Beam or had to be delivered on-demand by the Beam team - otherwise, around 60% of the workflow could’ve been built directly in Beam. We also gained experience working with early-stage software: occasional bugs were identified that slowed down development but also gave us valuable insights into the platform’s potential and limitations.",
    "oneSentencePitch": "CleanNest is an AI agent that brings structure to unstructured file systems by renaming documents based on their content and creating intuitive folder hierarchies - starting with Virtual Data Rooms, where every minute and every mistake costs real money.",
    "githubUrl": "",
    "videoUrl": "https://www.youtube.com/watch?v=rl0VE1FaJxY"
  },
  {
    "id": "project-9651",
    "name": "maintaino",
    "case": "beam",
    "whatIsProject": "Mainteno brings together all machine-related maintenance and predictive maintenance information into a single platform, which hosts AI agents that execute and coordinate the administrative and operational tasks. By leveraging real-time data and predictive analytics to anticipate equipment failures, procures spareparts and automate maintenance schedules, the platform enables plant and maintenance managers to focus on executing maintenance and strategic work, while reducing costly downtime and minimizing time spent on administrative tasks.",
    "howBuilt": "- Frontend: Lovable\n- Agent Orchestration: [Make.com](http://Make.com) / Beam\n- Foundation LLM: OpenAI gpt-3.5-turbo\n- Voice AI: ElevenLabs\n- Database: Supabase",
    "difficulties": "We lost significant time on two fronts: aligning on a single use case (we pivoted multiple times) and encountering issues with the Beam platform, which lacked debugging options. Additionally, limited technical development skills and time constraints hindered the full development of agent capabilities. Understanding the actual maintenance process for CNC machines also proved more complex than expected, requiring deeper insight into industry-specific workflows.",
    "oneSentencePitch": "Maintaino - the data-driven maintenance administration platform to keep your machines moving so your business never experiences downtimes",
    "githubUrl": "",
    "videoUrl": "https://www.youtube.com/watch?v=G_WgJGCT28s&ab_channel=Jo%C3%ABlHainzl",
    "demoUrl": "https://mindful-machine-mend.lovable.app"
  },
  {
    "id": "project-2827",
    "name": "Claid Legal",
    "case": "beam",
    "whatIsProject": "Claid Legal is an AI assistant that helps lawyers automate repetitive tasks and handle complex legal research. It answers legal questions, extracts information from documents, drafts emails, and enables editing of Word files with tracked changes. As a chat-based tool, it auto-selects the best LLMs, optimizes prompts, and asks clarifying questions when needed. With agentic deep research, Claid operates autonomously while always keeping the human in the loop. It integrates with Word and email, supports voice input, and ensures full GDPR compliance with all data processed in Germany.\n",
    "howBuilt": "We built a fully functional frontend and backend using FastAPI (Python), deployed on AWS for scalability and reliability. The frontend is developed with Next.js for a seamless user experience. Claid Legal leverages LangChain for prompt orchestration and reasoning, and integrates various LLMs including the newest Mistral for high-quality legal outputs. beam ai powers the legal (deep) research assistant logic. The system supports voice input, maintains a human in the loop at all times, is modular, privacy-focused, and optimized for legal workflows.",
    "difficulties": "Ensuring GDPR compliance and alignment with German legal ethics (BRAO) was challenging, especially when handling sensitive user data. Making the assistant more deterministic and predictable required fine-tuning prompts and model behavior—non-trivial given the complexity and ambiguity of legal language. Balancing powerful AI capabilities with strict legal standards demanded creative, domain-specific solutions. Custom beam tool integrations were challenging in the beginning.",
    "oneSentencePitch": "Claid Legal is an AI assistant for lawyers",
    "githubUrl": "https://github.com/Claid-Technologies/cdtm-agentic-research/",
    "videoUrl": "https://www.youtube.com/watch?v=5tSaxo_EQd4",
    "demoUrl": "https://www.aiguard.me/ -> Email: cdtm@claid.tech and Password: w.OkDp8g"
  },
  {
    "id": "project-8695",
    "name": "PromptRepublic",
    "case": "Trade Republic",
    "whatIsProject": "Our project is a finance app that allows users to explore their banking and trading data any way they want using plain English. Instead of navigating complex filters or spreadsheets, users can simply ask questions like “Show me my spending last month” or “Visualize my stock purchases by date,” and receive a tailored, interactive graph. It’s built for modern investors and consumers who want intuitive, conversational access to their financial insights—merging personalization, simplicity, and powerful analytics.",
    "howBuilt": "We used a React frontend with Vega-Lite for rendering dynamic visualizations, and a Python backend powered by FastAPI. The backend uses OpenAI’s GPT-4o API to interpret user prompts and generate valid Vega-Lite JSON specs. We handle two separate datasets—banking and trading—using Pandas, and use prompt engineering and an agent architecture to classify questions and select the appropriate dataset before building the visualization.",
    "difficulties": "We faced challenges in ensuring GPT-generated chart specs were valid, JSON-parseable, and aligned with user intent. Managing two data domains (banking vs. trading) required accurate prompt classification. We also had to solve data serialization issues and work around limitations in natural language understanding for ambiguous queries.",
    "oneSentencePitch": "A natural language-driven finance dashboard that turns user prompts into custom interactive data visualizations for both banking and trading activity.",
    "githubUrl": "https://github.com/juliusbrehme/CDTM",
    "videoUrl": "https://www.youtube.com/watch?v=HjkRbxvxlBQ",
    "demoUrl": "https://juliusbrehme.github.io/app/"
  },
  {
    "id": "project-5352",
    "name": "ValueBasedWealthManagement",
    "case": "Trade Republic",
    "whatIsProject": "Our vision is that people don’t save just to save, but to afford dreams and share with loved ones.  By extending Trade Republic, we enable collaborative, purpose-driven finance through shared accounts, joint savings goals, and insights into collective cashflows. Families can also open child accounts with limited permissions, thereby offering a guided financial journey. As kids grow, accounts convert automatically, onboarding the next generation at zero cost. While we focus on young professionals in partnerships and young families, this is only the beginning. Viewing the money in an account as a shared resource with varied access rights, permissions, and ownerships provides great potential to unfold in future ideations. ",
    "howBuilt": "Our focus was on ideating what current finance solutions are missing. The demo shown was implemented with Figma, no additional tools were used.",
    "difficulties": "We greatly appreciated the open-ended challenge, however, converging to a solution took us about half the time. After building our first prototype in Lovable, we quickly realized that it felt too fragmented, lacked narrative, and a clear purpose. To ensure that we can bring our ideas across in time, we used Figma to build our prototype. However, we believe that TradeRepublic is especially interested in new ideas and designs, just as we delivered.",
    "oneSentencePitch": "We enable collaborative purpose-driven finance along your life's journey.",
    "githubUrl": "",
    "videoUrl": "https://www.youtube.com/watch?v=BtFf5FfwRwA"
  },
  {
    "id": "project-9856",
    "name": "MCPublic",
    "case": "Trade Republic",
    "whatIsProject": "Problem: \nFinancial data is a confusing puzzle, with scattered pieces that retail investors and users struggle to understand. This makes it difficult for them to make informed investment decisions or gain insights into their spending and behavior. \n\nSolution: \nWe've built an AI-powered platform that integrates Trade Republic's trading data with natural language processing. Users can ask questions about their portfolio, trading history, or market data in natural language and get instant, intelligent responses. The LLM has access to functions that gather the necessary information to respond to user requests. MCP, a new technology, is only a couple of months old.",
    "howBuilt": "- Custom FastMCP framework for AI model integration.\n- Multiple MCP tools and resources to connect/manipulate the data.\n- Real-time WebSocket data retrieval.\n- Advanced fuzzy matching for financial instrument lookups.\n- Efficient data processing with Parquet storage.\n- Modern UI framework with React and TailwindCSS.",
    "difficulties": "MCP Framework Development: Discovering best practices\nDeveloping custom tooling for Mistral AI integration.\nAI-Finance Integration:\nEnsuring accurate financial data interpretation.\nUI/UX Innovation:\nSeamlessly integrating AI into Trade Republic's UI.\nCreating intuitive natural language interfaces.\nMaintaining design consistency.",
    "oneSentencePitch": "Trade Republic MCP makes personal finance simple and accessible, allowing anyone to understand their money through natural conversation, whether they're tracking daily expenses, planning savings, or managing investments.",
    "githubUrl": "https://github.com/JakobLiebig/trade-republic-mcp, https://github.com/blokth/blank-canvas-flowasdfasdf",
    "videoUrl": "https://www.youtube.com/watch?v=czbre6VeqYU",
    "demoUrl": "https://preview--blank-canvas-flow.lovable.app/"
  },
  {
    "id": "project-2432",
    "name": "SwipeRepublic",
    "case": "Trade Republic",
    "whatIsProject": "Our platform introduces 3 features: swipeable stock discovery, personalized news, and a yearly recap. Swiping helps users explore unfamiliar stocks and add them to their watchlist in a fun and engaging way. Stocks can be liked/disliked, with AI-driven buy/hold/sell tips and instant buy options. The \"Your Insights\" tab shows tailored news based on the user’s watchlist, community trading trends, as well as portfolio performance highlights. The annual recap, presented as stories, includes portfolio breakdowns, TR Card spending, Saveback/Round-Up impact, MSCI World comparisons, and shareable savings badges. Daily insights cover spending, saving, and market news. ",
    "howBuilt": "For the backend, we utilized Python in combination with the FastAPI framework, along with various utility libraries to support functionality and integration. On the frontend, we built the interface using TypeScript, Vite, and React, styled with TailwindCSS, and enhanced with several supporting libraries. For deployment, a live version of the demo has been successfully deployed using Vercel for the frontend and Render for the backend, ensuring accessibility and ease of use for mobile users. Additional tools were Lovable and ChatGPT.",
    "difficulties": "Initially we found it challenging to integrate the AI APIs into our project. We were really enthusiastic about the AI coding Tools provided but sooner than later realized that relying too much on them can cause greater difficulties and time waste in the future to connect the front- and backend. At certain times we also had issues with our internal communication and faced redundant work but we fixed it by using the Jira system and creating tickets to improve our work process. ",
    "oneSentencePitch": "SwipeRepublic, just a swipe away from investing in you.",
    "githubUrl": "https://github.com/CDTMFloMooJaKa/SwipeRepublic",
    "videoUrl": "https://www.youtube.com/watch?v=QG_v-Zfu9i4",
    "demoUrl": "https://trade-republic-replica-ui.vercel.app"
  },
  {
    "id": "project-8527",
    "name": "Trade public at Trade Republic",
    "case": "Trade Republic",
    "whatIsProject": "Our vision is to rethink the financial world by making trading public and immersing investors in a community.\nSince the pension gap is a problem of the whole society, we think we need a collaborative solution.\nWe’ve built an extension to the current TradeRepublic app, that brings a completely new community feature. It allows investors to track portfolios of their friends and other investors and provides them with a unique overview of their portfolios, scientific performance and risk analysis, as well as AI-generated explanations and insights.\nWith that we hope to normalize investing and motivate uneducated, intimidated newcomers to investments. However, it is central to our approach to integrate community the right way, not just headlines but always embracing champion integrity.",
    "howBuilt": "We specifically focused not only on building a working prototype, but also on a full end-to-end application, including a strong backend data structure and smart use of AI-models. Our frontend is built with TypeScript and React. Our data consists of both historical data, as well as also current stock prices derived from the TradeRepublic API. All of our data is stored within a PostgreSQL database. The backend is developed in Python with FastAPI, connecting frontend and backend through REST API endpoints. Moreover, we integrate the latest mistral-large model from the Mistral API to summarize user portfolios, recent friend activities and also personalized investment insights. The application is currently hosted on Heroku (backend) and GitHub Pages (frontend) and publicly available.",
    "difficulties": "First of all, the understanding of portfolios in a scientific way is challenging. However, a scientific risk analysis of a portfolio is strongly preferred and necessary to comply with our legacy banking approach.\nMoreover, the use and integration of the python library for this scientific risk analysis that calculate risk scores for a given set of data points was complicated to fit with our data format.",
    "oneSentencePitch": "We extend the TradeRepublic app with a community feature, which enables users to track portfolio updates of selected friends in order to facilitate the entry into the trading and investment world.",
    "githubUrl": "https://github.com/kevinfischer4/cdtmTR",
    "videoUrl": "https://www.youtube.com/watch?v=btB1ypOGnqA",
    "demoUrl": "https://kevinfischer4.github.io/cdtmTR/"
  }
];
